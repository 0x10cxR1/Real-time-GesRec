{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "# sys.path.append('../')\n",
    "os.chdir(\"/home/yxchen/Real-time-GesRec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(annotation_path='/home/yxchen/Real-time-GesRec/annotation_ems/ems07.1.json', arch='resnext-101', batch_size=1, begin_epoch=1, checkpoint=1, crop_position_in_test='c', dampening=0.9, dataset='ems', ft_begin_index=0, initial_scale=1.0, learning_rate=0.1, lr_patience=10, lr_steps=[10, 25, 50, 80, 100], manual_seed=1, mean=[114.7748, 107.7354, 99.475], mean_dataset='activitynet', modality='RGB', model='resnext', model_depth=101, momentum=0.9, n_classes=400, n_epochs=200, n_finetune_classes=10, n_scales=5, n_threads=1, n_val_samples=1, nesterov=False, no_cuda=False, no_hflip=False, no_mean_norm=False, no_softmax_in_test=False, no_train=False, no_val=False, norm_value=1, optimizer='sgd', pretrain_path='', resnet_shortcut='B', resnext_cardinality=32, result_path='/home/yxchen/Real-time-GesRec/results/ems07.1_test', resume_path='/home/yxchen/Real-time-GesRec/results/ems07/save_100.pth', root_path='/home/yxchen/Real-time-GesRec', sample_duration=32, sample_size=112, scale_in_test=1.0, scale_step=0.84089641525, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], std=[38.7568578, 37.88248729, 40.02898126], std_norm=False, store_name='model', test=False, test_subset='test', train_crop='corner', train_validate=False, video_path='/mnt/data/yxchen/gesture-datasets/ems', weight_decay=0.001, weighted=False, wide_resnet_k=2)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from opts import parse_opts_offline\n",
    "from model import generate_model\n",
    "from mean import get_mean, get_std\n",
    "from spatial_transforms import *\n",
    "from temporal_transforms import *\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose\n",
    "from dataset import get_training_set, get_validation_set, get_test_set, get_online_data\n",
    "from utils import Logger\n",
    "from train import train_epoch\n",
    "from validation import val_epoch\n",
    "import test\n",
    "from utils import AverageMeter, calculate_precision, calculate_recall\n",
    "import pdb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "opt = parse_opts_offline(\n",
    "['--root_path', '/home/yxchen/Real-time-GesRec', \n",
    " '--video_path', '/mnt/data/yxchen/gesture-datasets/ems', \n",
    " '--annotation_path', 'annotation_ems/ems07.1.json', \n",
    " '--result_path', 'results/ems07.1_test', \n",
    " '--resume_path', '/home/yxchen/Real-time-GesRec/results/ems07/save_100.pth', \n",
    " '--dataset', 'ems', \n",
    " '--sample_duration', '32', \n",
    " '--model', 'resnext',\n",
    " '--model_depth', '101',\n",
    " '--resnet_shortcut', 'B',\n",
    " '--batch_size', '1',\n",
    " '--n_finetune_classes', '10',\n",
    " '--n_threads', '1',\n",
    " '--checkpoint', '1',\n",
    " '--modality', 'RGB',\n",
    " '--n_val_samples', '1',\n",
    " '--test_subset', 'test']\n",
    ")\n",
    "if opt.root_path != '':\n",
    "    opt.video_path = os.path.join(opt.root_path, opt.video_path)\n",
    "    opt.annotation_path = os.path.join(opt.root_path, opt.annotation_path)\n",
    "    opt.result_path = os.path.join(opt.root_path, opt.result_path)\n",
    "    if opt.resume_path:\n",
    "        opt.resume_path = os.path.join(opt.root_path, opt.resume_path)\n",
    "    if opt.pretrain_path:\n",
    "        opt.pretrain_path = os.path.join(opt.root_path, opt.pretrain_path)\n",
    "opt.scales = [opt.initial_scale]\n",
    "for i in range(1, opt.n_scales):\n",
    "    opt.scales.append(opt.scales[-1] * opt.scale_step)\n",
    "opt.arch = '{}-{}'.format(opt.model, opt.model_depth)\n",
    "opt.mean = get_mean(opt.norm_value)\n",
    "opt.std = get_std(opt.norm_value)\n",
    "\n",
    "print(opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def calculate_accuracy(outputs, targets, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = targets.size(0)\n",
    "    _, pred = outputs.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1).expand_as(pred))\n",
    "    ret = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].float().sum().item()\n",
    "        ret.append(correct_k / batch_size)\n",
    "\n",
    "    return ret\n",
    "\n",
    "if not os.path.exists(opt.result_path):\n",
    "    os.makedirs(opt.result_path)\n",
    "\n",
    "with open(os.path.join(opt.result_path, 'opts.json'), 'w') as opt_file:\n",
    "    json.dump(vars(opt), opt_file)\n",
    "\n",
    "torch.manual_seed(opt.manual_seed)\n",
    "\n",
    "model, parameters = generate_model(opt)\n",
    "# print(model)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if\n",
    "                           p.requires_grad)\n",
    "print(\"Total number of trainable parameters: \", pytorch_total_params)\n",
    "\n",
    "if opt.no_mean_norm and not opt.std_norm:\n",
    "    norm_method = Normalize([0, 0, 0], [1, 1, 1])\n",
    "elif not opt.std_norm:\n",
    "    norm_method = Normalize(opt.mean, [1, 1, 1])\n",
    "else:\n",
    "    norm_method = Normalize(opt.mean, opt.std)\n",
    "\n",
    "# original\n",
    "spatial_transform = Compose([\n",
    "    #Scale(opt.sample_size),\n",
    "    Scale(112),\n",
    "    CenterCrop(112),\n",
    "    ToTensor(opt.norm_value), norm_method\n",
    "    ])\n",
    "\n",
    "temporal_transform = TemporalCenterCrop(opt.sample_duration)\n",
    "\n",
    "target_transform = ClassLabel()\n",
    "test_data = get_test_set(\n",
    "    opt, spatial_transform, temporal_transform, target_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_data,\n",
    "            batch_size=opt.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=opt.n_threads,\n",
    "            pin_memory=True)\n",
    "test_logger = Logger(os.path.join(opt.result_path, 'test.log'),\n",
    " [ 'top1', 'top5', 'precision', 'recall'])\n",
    "\n",
    "\n",
    "if opt.resume_path:\n",
    "    print('loading checkpoint {}'.format(opt.resume_path))\n",
    "    checkpoint = torch.load(opt.resume_path)\n",
    "    assert opt.arch == checkpoint['arch']\n",
    "\n",
    "    opt.begin_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "#test.test(test_loader, model, opt, test_data.class_names)\n",
    "\n",
    "recorder = []\n",
    "\n",
    "print('run')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "batch_time = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "precisions = AverageMeter() #\n",
    "recalls = AverageMeter()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "end_time = time.time()\n",
    "\n",
    "# fout = open(os.path.join(opt.result_path, 'result.csv'), 'w')\n",
    "\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "    if not opt.no_cuda:\n",
    "        targets = targets.cuda(non_blocking=True)\n",
    "    #inputs = Variable(torch.squeeze(inputs), volatile=True)\n",
    "    with torch.no_grad():\n",
    "        inputs = Variable(inputs)\n",
    "        targets = Variable(targets)\n",
    "        outputs = model(inputs)\n",
    "        if not opt.no_softmax_in_test:\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "        recorder.append(outputs.data.cpu().numpy().copy())\n",
    "    y_true.extend(targets.cpu().numpy().tolist())\n",
    "    y_pred.extend(outputs.argmax(1).cpu().numpy().tolist())\n",
    "\n",
    "    _cls = outputs.argmax(1).cpu().numpy().tolist()[0]\n",
    "\n",
    "    if outputs.size(1) <= 4:\n",
    "\n",
    "        prec1= calculate_accuracy(outputs, targets, topk=(1,))\n",
    "        precision = calculate_precision(outputs, targets) #\n",
    "        recall = calculate_recall(outputs,targets)\n",
    "\n",
    "\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        precisions.update(precision, inputs.size(0))\n",
    "        recalls.update(recall,inputs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end_time)\n",
    "        end_time = time.time()\n",
    "\n",
    "#         print('[{0}/{1}]\\t'\n",
    "#               'Time {batch_time.val:.5f} ({batch_time.avg:.5f})\\t'\n",
    "#               'prec@1 {top1.avg:.5f} \\t'\n",
    "#               'precision {precision.val:.5f} ({precision.avg:.5f})\\t'\n",
    "#               'recall {recall.val:.5f} ({recall.avg:.5f})'.format(\n",
    "#                   i + 1,\n",
    "#                   len(test_loader),\n",
    "#                   batch_time=batch_time,\n",
    "#                   top1 =top1,\n",
    "#                   precision = precisions,\n",
    "#                   recall = recalls))\n",
    "    else:\n",
    "\n",
    "        prec1, prec5 = calculate_accuracy(outputs, targets, topk=(1,5))\n",
    "        precision = calculate_precision(outputs, targets) #\n",
    "        recall = calculate_recall(outputs,targets)\n",
    "\n",
    "\n",
    "        top1.update(prec1, inputs.size(0))\n",
    "        top5.update(prec5, inputs.size(0))\n",
    "        precisions.update(precision, inputs.size(0))\n",
    "        recalls.update(recall,inputs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end_time)\n",
    "        end_time = time.time()\n",
    "#         print('[{0}/{1}]\\t'\n",
    "#               'Time {batch_time.val:.5f} ({batch_time.avg:.5f})\\t'\n",
    "#               'prec@1 {top1.avg:.5f} prec@5 {top5.avg:.5f}\\t'\n",
    "#               'precision {precision.val:.5f} ({precision.avg:.5f})\\t'\n",
    "#               'recall {recall.val:.5f} ({recall.avg:.5f})'.format(\n",
    "#                   i + 1,\n",
    "#                   len(test_loader),\n",
    "#                   batch_time=batch_time,\n",
    "#                   top1 =top1,\n",
    "#                   top5=top5,\n",
    "#                   precision = precisions,\n",
    "#                   recall = recalls))\n",
    "test_logger.log({\n",
    "        'top1': top1.avg,\n",
    "        'top5': top5.avg,\n",
    "        'precision':precisions.avg,\n",
    "        'recall':recalls.avg\n",
    "    })\n",
    "\n",
    "print('-----Evaluation is finished------')\n",
    "print('Overall Prec@1 {:.05f}% Prec@5 {:.05f}%'.format(top1.avg, top5.avg))\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred).astype(float)\n",
    "\n",
    "cls_cnt = cf.sum(axis=1)\n",
    "cls_hit = np.diag(cf)\n",
    "cls_acc = cls_hit / cls_cnt\n",
    "#print('Class Accuracy {:.02f}%'.format(cls_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 arm_down_right : 94.12%\n",
      "1 arm_down_left : 11.76%\n",
      "2 wrist_right : 78.85%\n",
      "3 wrist_down : 15.38%\n",
      "4 wrist_left : 13.46%\n",
      "5 down_left : 86.54%\n",
      "6 arm_down : 55.77%\n",
      "7 up_right : 46.15%\n",
      "8 wrist_up : 36.54%\n",
      "9 up_left : 98.08%\n",
      "Normalized confusion matrix\n",
      "Confusion matrix plotted\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_cm(cm, classes=None, normalize = True):\n",
    "    import seaborn as sns\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=False, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.yticks(rotation='horizontal')\n",
    "\n",
    "    print(\"Confusion matrix plotted\")\n",
    "\n",
    "for i in range(len(test_data.class_names)):\n",
    "    print(i, test_data.class_names[i], ': {:.02f}%'.format(cls_acc[i]*100))\n",
    "plot_cm(cf)\n",
    "\n",
    "# print(\"y_true, y_pred\")\n",
    "# for i in range(len(y_true)):\n",
    "#     print(y_true[i], y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ems]",
   "language": "python",
   "name": "conda-env-ems-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
